Copyright © Microsoft Corporation. All rights reserved.
  适用于[License](https://github.com/Microsoft/ai-edu/blob/master/LICENSE.md)版权许可

# 搭积木 - 非线性回归

在第九章中，我们用一个两层的神经网络，验证了万能近似定理。当时是用hard code方式写的，现在我们用mini框架来搭建一下。

## 数据

```Python
def LoadData():
    dataReader = DataReader(x_data_name, y_data_name)
    dataReader.ReadData()
    dataReader.Normalize(False, False, False)
    return dataReader
```

数据部分的code，基本是通用的。Normalize方法有一些参数，可以控制是否归一化X值、归一化Y值、是否把标签转换成One-hot形式。对于本例，X和Y值已经处于[0,1]空间了，不需要归一化，所以是两个False。由于是回归任务，所以也不需要转One-hot编码。

## 可视化结果

```Python
def ShowResult(net, dataReader, title):
    # draw train data
    plt.plot(dataReader.X[0,:], dataReader.Y[0,:], '.', c='b')
    # create and draw visualized validation data
    TX = np.linspace(0,1,100).reshape(1,100)
    TY = net.inference(TX)
    plt.plot(TX, TY, 'x', c='r')
    plt.title(title)
    plt.show()
```

## 搭建模型

<img src='./Images/14/non_linear_regression.png'/>

```Python
if __name__ == '__main__':
    dataReader = LoadData()
    num_input = 1
    num_hidden1 = 4
    num_output = 1

    max_epoch = 10000
    batch_size = 10
    learning_rate = 0.5
    eps = 0.001

    params = CParameters(learning_rate, max_epoch, batch_size, eps,
                        LossFunctionName.MSE, 
                        InitialMethod.Xavier, 
                        OptimizerName.SGD)

    net = NeuralNet(params)
    fc1 = FcLayer(num_input, num_hidden1, params)
    net.add_layer(fc1, "fc1")
    sigmoid1 = ActivatorLayer(Sigmoid())
    net.add_layer(sigmoid1, "sigmoid1")
    fc2 = FcLayer(num_hidden1, num_output, params)
    net.add_layer(fc2, "fc2")

    net.train(dataReader, checkpoint=10, need_test=False)
    net.ShowLossHistory()
    
    ShowResult(net, dataReader, params.toString())
```

1. 先构造一个参数集合CParameters，包括：
   1. 学习率
   2. 最大epoch
   3. 批大小
   4. eps停止条件
   5. 损失函数形态(MSE均方差)
   6. 初始化方法(default为Xavier)
   7. 优化器选择default为(SGD)
2. 构造网络NeuralNet，传入参数
3. 构造第一个FC层，指定输入样本特征数量和输出（num_hidden1）神经元个数值，及Sigmoid激活函数
4. 构造第二个FC层，指定输入和输出尺寸，因为是回归任务，所以没有分类函数
5. 开始训练，并传入DataReader实例

net.train()函数是一个阻塞函数，只有当训练完毕后才返回。

# 代码位置

ch14, Level1

# 数据来源

Dua, D. and Graff, C. (2019). UCI Machine Learning Repository [http://archive.ics.uci.edu/ml]. Irvine, CA: University of California, School of Information and Computer Science.

